{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "531734b6",
   "metadata": {},
   "source": [
    "# A Tour of Transformer Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16cbc131",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8727601",
   "metadata": {},
   "source": [
    "## Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1929ee40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dear Amazon, last week I ordered an Optimus Prime action figure \\nfrom your online store in Germany. Unfortunately, when I opened the package, \\nI discovered to my horror that I had been sent an action figure of Megatron \\ninstead! As a lifelong enemy of the Deceptions, I hope you can understand my \\ndilemma. TO resolve the issue, I demand an exchange of Megatron for the \\nOptimus Prime figure I ordered. Enclosed are copies of my records concerning \\nthis purchase. I expect to hear from you soon. Sincerely, Bumblebee.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"Dear Amazon, last week I ordered an Optimus Prime action figure \n",
    "from your online store in Germany. Unfortunately, when I opened the package, \n",
    "I discovered to my horror that I had been sent an action figure of Megatron \n",
    "instead! As a lifelong enemy of the Deceptions, I hope you can understand my \n",
    "dilemma. TO resolve the issue, I demand an exchange of Megatron for the \n",
    "Optimus Prime figure I ordered. Enclosed are copies of my records concerning \n",
    "this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\"\"\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04898192",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'task': 'text-classification',\n",
       " 'model': DistilBertForSequenceClassification(\n",
       "   (distilbert): DistilBertModel(\n",
       "     (embeddings): Embeddings(\n",
       "       (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "       (position_embeddings): Embedding(512, 768)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (transformer): Transformer(\n",
       "       (layer): ModuleList(\n",
       "         (0-5): 6 x TransformerBlock(\n",
       "           (attention): MultiHeadSelfAttention(\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "             (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "           )\n",
       "           (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (ffn): FFN(\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "             (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (activation): GELUActivation()\n",
       "           )\n",
       "           (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "   (dropout): Dropout(p=0.2, inplace=False)\n",
       " ),\n",
       " 'tokenizer': DistilBertTokenizerFast(name_or_path='distilbert/distilbert-base-uncased-finetuned-sst-2-english', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       " \t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " },\n",
       " 'feature_extractor': None,\n",
       " 'image_processor': None,\n",
       " 'modelcard': None,\n",
       " 'framework': 'pt',\n",
       " 'device': device(type='cpu'),\n",
       " 'torch_dtype': None,\n",
       " 'binary_output': False,\n",
       " 'call_count': 0,\n",
       " '_batch_size': None,\n",
       " '_num_workers': None,\n",
       " '_preprocess_params': {},\n",
       " '_forward_params': {},\n",
       " '_postprocess_params': {}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"text-classification\")\n",
    "classifier.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6a1ac53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66955010"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fea61c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'NEGATIVE', 'score': 0.8406198620796204}]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.84062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label    score\n",
       "0  NEGATIVE  0.84062"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = classifier(text)\n",
    "print(outputs)\n",
    "pd.DataFrame(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56eae2d",
   "metadata": {},
   "source": [
    "## Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00e37dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'task': 'ner',\n",
       " 'model': BertForTokenClassification(\n",
       "   (bert): BertModel(\n",
       "     (embeddings): BertEmbeddings(\n",
       "       (word_embeddings): Embedding(28996, 1024, padding_idx=0)\n",
       "       (position_embeddings): Embedding(512, 1024)\n",
       "       (token_type_embeddings): Embedding(2, 1024)\n",
       "       (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (encoder): BertEncoder(\n",
       "       (layer): ModuleList(\n",
       "         (0-23): 24 x BertLayer(\n",
       "           (attention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "               (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "               (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "               (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): BertIntermediate(\n",
       "             (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): BertOutput(\n",
       "             (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "             (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       "   (classifier): Linear(in_features=1024, out_features=9, bias=True)\n",
       " ),\n",
       " 'tokenizer': BertTokenizerFast(name_or_path='dbmdz/bert-large-cased-finetuned-conll03-english', vocab_size=28996, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       " \t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " },\n",
       " 'feature_extractor': None,\n",
       " 'image_processor': None,\n",
       " 'modelcard': None,\n",
       " 'framework': 'pt',\n",
       " 'device': device(type='cpu'),\n",
       " 'torch_dtype': None,\n",
       " 'binary_output': False,\n",
       " 'call_count': 0,\n",
       " '_batch_size': None,\n",
       " '_num_workers': None,\n",
       " '_preprocess_params': {},\n",
       " '_forward_params': {},\n",
       " '_postprocess_params': {'aggregation_strategy': <AggregationStrategy.SIMPLE: 'simple'>},\n",
       " '_basic_tokenizer': <transformers.models.bert.tokenization_bert.BasicTokenizer at 0x7fc7da3bbd90>,\n",
       " '_args_parser': <transformers.pipelines.token_classification.TokenClassificationArgumentHandler at 0x7fc7e0164810>}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_tagger = pipeline(\"ner\", aggregation_strategy=\"simple\")\n",
    "ner_tagger.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bac87ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_group</th>\n",
       "      <th>score</th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.913283</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.993152</td>\n",
       "      <td>Optimus Prime</td>\n",
       "      <td>36</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOC</td>\n",
       "      <td>0.999755</td>\n",
       "      <td>Germany</td>\n",
       "      <td>91</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.633205</td>\n",
       "      <td>Mega</td>\n",
       "      <td>210</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PER</td>\n",
       "      <td>0.546527</td>\n",
       "      <td>##tron</td>\n",
       "      <td>214</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.809585</td>\n",
       "      <td>Deceptions</td>\n",
       "      <td>256</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.818338</td>\n",
       "      <td>Megatron</td>\n",
       "      <td>353</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.991682</td>\n",
       "      <td>Optimus Prime</td>\n",
       "      <td>371</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PER</td>\n",
       "      <td>0.810429</td>\n",
       "      <td>Bumblebee</td>\n",
       "      <td>507</td>\n",
       "      <td>516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  entity_group     score           word  start  end\n",
       "0          ORG  0.913283         Amazon      5   11\n",
       "1         MISC  0.993152  Optimus Prime     36   49\n",
       "2          LOC  0.999755        Germany     91   98\n",
       "3         MISC  0.633205           Mega    210  214\n",
       "4          PER  0.546527         ##tron    214  218\n",
       "5          ORG  0.809585     Deceptions    256  266\n",
       "6         MISC  0.818338       Megatron    353  361\n",
       "7         MISC  0.991682  Optimus Prime    371  384\n",
       "8          PER  0.810429      Bumblebee    507  516"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = ner_tagger(text)\n",
    "pd.DataFrame(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc44d045",
   "metadata": {},
   "source": [
    "## Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "637448fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'task': 'question-answering',\n",
       " 'model': DistilBertForQuestionAnswering(\n",
       "   (distilbert): DistilBertModel(\n",
       "     (embeddings): Embeddings(\n",
       "       (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "       (position_embeddings): Embedding(512, 768)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (transformer): Transformer(\n",
       "       (layer): ModuleList(\n",
       "         (0-5): 6 x TransformerBlock(\n",
       "           (attention): MultiHeadSelfAttention(\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "             (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "           )\n",
       "           (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (ffn): FFN(\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "             (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (activation): GELUActivation()\n",
       "           )\n",
       "           (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'tokenizer': DistilBertTokenizerFast(name_or_path='distilbert/distilbert-base-cased-distilled-squad', vocab_size=28996, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       " \t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " },\n",
       " 'feature_extractor': None,\n",
       " 'image_processor': None,\n",
       " 'modelcard': None,\n",
       " 'framework': 'pt',\n",
       " 'device': device(type='cpu'),\n",
       " 'torch_dtype': None,\n",
       " 'binary_output': False,\n",
       " 'call_count': 0,\n",
       " '_batch_size': None,\n",
       " '_num_workers': None,\n",
       " '_preprocess_params': {},\n",
       " '_forward_params': {},\n",
       " '_postprocess_params': {},\n",
       " '_args_parser': <transformers.pipelines.question_answering.QuestionAnsweringArgumentHandler at 0x7fc7c41bfb50>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = pipeline(\"question-answering\")\n",
    "reader.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c03c36d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.679738</td>\n",
       "      <td>338</td>\n",
       "      <td>361</td>\n",
       "      <td>an exchange of Megatron</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score  start  end                   answer\n",
       "0  0.679738    338  361  an exchange of Megatron"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What does the customer want?\"\n",
    "outputs = reader(question=question, context=text)\n",
    "pd.DataFrame([outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc8076f",
   "metadata": {},
   "source": [
    "## Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08058db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8bd1279f0bd4c64b1c13184e8f4412e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bb84d5179d44b25b85cd94f857fb20a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13f0de50045f4274aa3baf4636c73217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf9110eaa59e4fd2bf84eae7afeba4ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b4699cef5304d92a422884ba62522a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'task': 'summarization',\n",
       " 'model': BartForConditionalGeneration(\n",
       "   (model): BartModel(\n",
       "     (shared): Embedding(50264, 1024, padding_idx=1)\n",
       "     (encoder): BartEncoder(\n",
       "       (embed_tokens): Embedding(50264, 1024, padding_idx=1)\n",
       "       (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "       (layers): ModuleList(\n",
       "         (0-11): 12 x BartEncoderLayer(\n",
       "           (self_attn): BartSdpaAttention(\n",
       "             (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "             (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "             (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "             (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "           )\n",
       "           (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "           (activation_fn): GELUActivation()\n",
       "           (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "           (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "           (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "       (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "     )\n",
       "     (decoder): BartDecoder(\n",
       "       (embed_tokens): Embedding(50264, 1024, padding_idx=1)\n",
       "       (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "       (layers): ModuleList(\n",
       "         (0-5): 6 x BartDecoderLayer(\n",
       "           (self_attn): BartSdpaAttention(\n",
       "             (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "             (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "             (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "             (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "           )\n",
       "           (activation_fn): GELUActivation()\n",
       "           (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "           (encoder_attn): BartSdpaAttention(\n",
       "             (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "             (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "             (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "             (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "           )\n",
       "           (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "           (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "           (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "           (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "       (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       "   (lm_head): Linear(in_features=1024, out_features=50264, bias=False)\n",
       " ),\n",
       " 'tokenizer': BartTokenizerFast(name_or_path='sshleifer/distilbart-cnn-12-6', vocab_size=50265, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       " \t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       " \t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       " \t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       " \t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       " \t50264: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n",
       " },\n",
       " 'feature_extractor': None,\n",
       " 'image_processor': None,\n",
       " 'modelcard': None,\n",
       " 'framework': 'pt',\n",
       " 'device': device(type='cpu'),\n",
       " 'torch_dtype': None,\n",
       " 'binary_output': False,\n",
       " 'call_count': 0,\n",
       " '_batch_size': None,\n",
       " '_num_workers': None,\n",
       " '_preprocess_params': {},\n",
       " '_forward_params': {},\n",
       " '_postprocess_params': {}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\")\n",
    "summarizer.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c78069f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your min_length=56 must be inferior than your max_length=45.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mount/studenten/arbeitsdaten-studenten1/shencg/condaenvs/nlp-with-transformers/lib/python3.11/site-packages/transformers/generation/utils.py:1156: UserWarning: Unfeasible length constraints: `min_length` (56) is larger than the maximum possible length (45). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bumblebee ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when he opened the package, he discovered to his horror that he had been sent an action figure of Megatron instead.\n"
     ]
    }
   ],
   "source": [
    "outputs = summarizer(text, max_length=45, clean_up_tokenization_spaces=True)\n",
    "print(outputs[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c6b20b",
   "metadata": {},
   "source": [
    "## Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "223874d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfdf48a1644248789cc2805a267ffd00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "source.spm:   0%|          | 0.00/768k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc3163c1585941b2acca98b3ce7a2c14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "target.spm:   0%|          | 0.00/797k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e1d80c214e48c8a62f3dd576d392ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.27M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mount/studenten/arbeitsdaten-studenten1/shencg/condaenvs/nlp-with-transformers/lib/python3.11/site-packages/transformers/models/marian/tokenization_marian.py:197: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'task': 'translation_en_to_de',\n",
       " 'model': MarianMTModel(\n",
       "   (model): MarianModel(\n",
       "     (shared): Embedding(58101, 512, padding_idx=58100)\n",
       "     (encoder): MarianEncoder(\n",
       "       (embed_tokens): Embedding(58101, 512, padding_idx=58100)\n",
       "       (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
       "       (layers): ModuleList(\n",
       "         (0-5): 6 x MarianEncoderLayer(\n",
       "           (self_attn): MarianAttention(\n",
       "             (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "           )\n",
       "           (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "           (activation_fn): SiLU()\n",
       "           (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "           (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "           (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (decoder): MarianDecoder(\n",
       "       (embed_tokens): Embedding(58101, 512, padding_idx=58100)\n",
       "       (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
       "       (layers): ModuleList(\n",
       "         (0-5): 6 x MarianDecoderLayer(\n",
       "           (self_attn): MarianAttention(\n",
       "             (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "           )\n",
       "           (activation_fn): SiLU()\n",
       "           (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "           (encoder_attn): MarianAttention(\n",
       "             (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "           )\n",
       "           (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "           (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "           (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "           (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (lm_head): Linear(in_features=512, out_features=58101, bias=False)\n",
       " ),\n",
       " 'tokenizer': MarianTokenizer(name_or_path='Helsinki-NLP/opus-mt-en-de', vocab_size=58101, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       " \t0: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t1: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t58100: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " },\n",
       " 'feature_extractor': None,\n",
       " 'image_processor': None,\n",
       " 'modelcard': None,\n",
       " 'framework': 'pt',\n",
       " 'device': device(type='cpu'),\n",
       " 'torch_dtype': None,\n",
       " 'binary_output': False,\n",
       " 'call_count': 0,\n",
       " '_batch_size': None,\n",
       " '_num_workers': None,\n",
       " '_preprocess_params': {'src_lang': 'en', 'tgt_lang': 'de'},\n",
       " '_forward_params': {},\n",
       " '_postprocess_params': {}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator = pipeline(\"translation_en_to_de\", model=\"Helsinki-NLP/opus-mt-en-de\")\n",
    "translator.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d97da33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liebe Amazon, letzte Woche habe ich eine Optimus Prime Action Figur von Ihrem Online-Shop in Deutschland bestellt. Leider, als ich das Paket öffnete, entdeckte ich zu meinem Entsetzen, dass ich stattdessen eine Action Figur von Megatron geschickt worden war! Als lebenslanger Feind der Täuschungen, hoffe ich, dass Sie mein Dilemma verstehen können. Um das Problem zu lösen, fordere ich einen Austausch von Megatron für die von mir bestellte Optimus Prime Figur. Anbei sind Kopien meiner Aufzeichnungen über diesen Kauf. Ich erwarte, bald von Ihnen zu hören. Aufrichtig, Bumblebee.\n"
     ]
    }
   ],
   "source": [
    "outputs = translator(text, clean_up_tokenization_spaces=True, min_length=100)\n",
    "print(outputs[0]['translation_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53f265b",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83b6359a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 6c0e608 (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b14c73bc97e74376aef7e783db24755d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eb7f5ac744d4fe9acae00a87efec607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a52fc6e0b3564a75b52424f6cd157c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04b5429ddb0b407e9eacab7006966804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b86c3660e344fd9cee4161e27c6e44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3048ea4bf934730b21859384dc61724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10be417c1be84bd382b31c9f477f265b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'task': 'text-generation',\n",
       " 'model': GPT2LMHeadModel(\n",
       "   (transformer): GPT2Model(\n",
       "     (wte): Embedding(50257, 768)\n",
       "     (wpe): Embedding(1024, 768)\n",
       "     (drop): Dropout(p=0.1, inplace=False)\n",
       "     (h): ModuleList(\n",
       "       (0-11): 12 x GPT2Block(\n",
       "         (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "         (attn): GPT2Attention(\n",
       "           (c_attn): Conv1D()\n",
       "           (c_proj): Conv1D()\n",
       "           (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "           (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "         (mlp): GPT2MLP(\n",
       "           (c_fc): Conv1D()\n",
       "           (c_proj): Conv1D()\n",
       "           (act): NewGELUActivation()\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   )\n",
       "   (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       " ),\n",
       " 'tokenizer': GPT2TokenizerFast(name_or_path='openai-community/gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       " \t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       " },\n",
       " 'feature_extractor': None,\n",
       " 'image_processor': None,\n",
       " 'modelcard': None,\n",
       " 'framework': 'pt',\n",
       " 'device': device(type='cpu'),\n",
       " 'torch_dtype': None,\n",
       " 'binary_output': False,\n",
       " 'call_count': 0,\n",
       " '_batch_size': None,\n",
       " '_num_workers': None,\n",
       " '_preprocess_params': {'add_special_tokens': False,\n",
       "  'truncation': None,\n",
       "  'padding': False,\n",
       "  'max_length': None},\n",
       " '_forward_params': {},\n",
       " '_postprocess_params': {}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\")\n",
    "generator.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bffb5b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear Amazon, last week I ordered an Optimus Prime action figure \n",
      "from your online store in Germany. Unfortunately, when I opened the package, \n",
      "I discovered to my horror that I had been sent an action figure of Megatron \n",
      "instead! As a lifelong enemy of the Deceptions, I hope you can understand my \n",
      "dilemma. TO resolve the issue, I demand an exchange of Megatron for the \n",
      "Optimus Prime figure I ordered. Enclosed are copies of my records concerning \n",
      "this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\n",
      "\n",
      "Customer service response:\n",
      "Dear Bumblebee, I am sorry to hear that your order was mixed up. Please contact me within 48 hours and we will make an official statement, provided i am able to return and return  this item. For your e-mail, please click here. The return package included a \"Product Refund Policy\" for the shipment. Thank\n"
     ]
    }
   ],
   "source": [
    "response = \"Dear Bumblebee, I am sorry to hear that your order was mixed up.\"\n",
    "prompt = text + \"\\n\\nCustomer service response:\\n\" + response\n",
    "outputs = generator(prompt, max_length=200)\n",
    "print(outputs[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a396099",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
